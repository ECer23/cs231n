**IMPORTANT:** Please view documents on [Github Pages](http://ecr23.me/cs231n)

## Contents

* [1 - Classifier](1-Classifier) kNN, SVM, Softmax and basic Neural Network classifier.
* [2 - Convolutional Neural Network](2-Convolutional-Neural-Network) ConvNets architecture design, fine tuning tips and vectorized implementation details.
* [3 - ConvNets Training Tips](3-ConvNets-Training-Tips) Tips on setting up data, model and loss functions to boost your ConvNets training

## Motivation
When I'm doing another project that based on [yolov3.pytorch](https://github.com/ECer23/yolov3.pytorch), I came across a problem in Batch Normalization. My understanding of BN just limits in `nn.BatchNorm`, and when I want to do things like computing accumulated gradients, I got stuck in because I'm not familiar with computation of running mean/variance or something like that. This is the motivation of doing CS231n assignments again. I hope it could push me to revise those classical algorithms, and go beyond than just knowing interfaces of PyTorch or TensorFlow.

## General plans
In general, I will finish every part of this assignments (again), and writing down what I learnt in such a learning process. If you want to catch up with the latest updates, please click "**Subscribe**" in the right. Updates in this issue will be sent to your GitHub Notification Center.
